\documentclass[11pt]{article}
\RequirePackage[l2tabu, orthodox]{nag}
\RequirePackage{fullpage}
\RequirePackage{amsmath,amssymb,amsthm}
\RequirePackage{graphicx}
\RequirePackage{bm}
\RequirePackage{bbm}
\RequirePackage{mathrsfs}
\RequirePackage[citestyle=authoryear,maxbibnames=9,maxcitenames=2,backend=biber,natbib=true]{biblatex}
\RequirePackage[x11names, rgb]{xcolor}
\RequirePackage{todonotes}
\RequirePackage{tikz}
\usetikzlibrary{decorations,arrows,shapes}
\RequirePackage[colorlinks=true]{hyperref}

\renewcommand{\P}{\mathbb{P}}
\newcommand{\E}{\mathbb{E}}
\DeclareMathOperator{\var}{var}
\DeclareMathOperator{\cov}{cov}

\addbibresource{stoch.bib}

\title{Math Notes}

\author{Vince Buffalo}

\begin{document}
\maketitle


% Thinking about markov chains as accounting of netflow in and netflow out of a
% state. We should be able to solve it this way too. Reccurence relations as
% infinite sums (well, over t-> N)
% 
% popgen stuff:
%  - infinite population limit -> modeling frequencies
%  - rescaling time

\section{Generating Functions}

Generating functions encode a sequence of numbers, $a_0, a_1, a_2, \ldots$. A
\emph{generating function} $A(s)$ is a series:

\begin{align*}
  A(s) &= a_0 + a_1 s + a_2 s^2 + \ldots\\
  A(s) &= \sum_{k=0}^\infty a_k s^k
\end{align*}

This converges for $|s| < 1$, but we aren't explicitly interested in
convergence. As Wilf says in \citep{wilf2013generatingfunctionology}, ``we can
think of a generating function as only a formal power series, i.e., as an
algebraic object rather than as an analytic one."

Generating functions are tremendously useful as they encode a sequence of
numbers in a function, which can then be easily manipulated. 

\subsection{Probability Generating Functions}

We can use generating functions to encode probabilities:

\begin{align*}
  P(s) &= p_0 + p_1 s + p_2 s^2 + \ldots\\
  P(s) &= \E[s^X]\\
\end{align*}

where $\P(X = k) = p_k$. This is a \emph{probability generation function} and
it's useful for calculating quantities expectations and sums of random
variables. As with generating functions, we're not explicitly interested in
convergence, but rather in manipulating the encoded sequence as a function.

For example, we can find the expected value $\E[X]$ by taking the first
derivative of $P(s)$:

\begin{align*}
  P'(s) &= p_1 + p_2 s + 2 p_3 s^2 + \ldots\\
  P'(s) &= \sum_{k = 1} k p_k s^{k-1}
\end{align*}

By setting $s=1$, this formally reduces to $\sum k p_k$, which we recognize as
the expectation of $X$, $\E[X] = \sum k p_k$. Thus, we say:

\begin{align*}
  \label{eq:gen-func-thm-01}
    \E[X] = P'(1) 
\end{align*}

\subsection{Convolutions}

Convolutions are incredibly useful throughout the theory of probability and
stochastic processes, and are a terrific of example of how generating functions
are useful. For example, the sum of two discrete random variables $Z = X + Y$
has a PMF defined by:

$$
\P(Z = z) = \P(X + Y = z) = \sum_{k=0}^z P(X=k) P(Y=z-k)
$$

Intuitively, the event $Z=z$ can happen many different ways, and the equation
above enumerates all these possible ways. For example, if $Z=2$, this could
occur if $X=0$ and $Y=2$, $X=1$ and $Y=1$, or $X=2$ and $Y=0$. The sum above is
a \emph{convolution}. For generating functions $A(s)$ and $B(s)$ of random
variables $X$ and $Y$ respectively, the generating function of their
convolution is:

\begin{align*}
  C(s) &= A(s)B(s) = \sum_{k=0}^\infty a_k s^k \cdot \sum_{k=0}^\infty b_k s^k \\
  C(s) &= ( a_0 + a_1 s + a_2 s^2 + \ldots ) (b_0 + b_1 s + b_2 s^2 + \ldots)\\
  C(s) &= \sum_{k=0}^\infty \left( \sum_{j=0}^k a_j b_{k-j} \right) s^k
\end{align*}

or,

$$
C(s) = \sum_{k=0}^\infty c_n s^k
$$

where

$$
c_n = \sum_{j=0}^k a_j b_{k-j}
$$

Thus, the PMF of $Z$ has the probability generating function $C(s)$.

Generating functions are also used to tackle problems like recurrence equations
and enumerate problems in combinatorics; see
\citep{wilf2013generatingfunctionology} for a full treatment on generating
functions.

\section{Recurrent Events}






\section{Markov Chains}

Beauty of markov chains: 

superficially: eigenvalue eigenvector decomp for purely computational reasons, e.g. $P^n$. 

But then, how this relates algebraically to things

probability and LIMIT consequences.

\paragraph{Eigenvalues and Perron-Frobenius}

Stochastic matrices must have an eigenvalue $\lambda_1 = 1$ and corresponding
eigenvector $v_1 = \mathbf{1}$. Why? Each row of a right stochastic matrix must
sum to one (in other words, rows of stochastic matrices need to follow the
second axiom or probability: unit measure):

$$
\sum_{j} M_{i,j} = 1
$$

Alternatively, we can express this in matrix form:

$$
\mathbf{1}^T \mathbf{M} = \mathbf{1}^T
$$

which makes it clear that 1 is a left eigenvalue of $\mathbf{M}$ since an left
eigenvalue is some $\lambda$ such that $\mathbf{v} \mathbf{A} = \lambda
\mathbf{v}$. 

Furthermore, this eigenvalue $\lambda_1$ is the dominant
eigenvalue, $\lambda_i < 1, i \ne 1$.

% TODO: PF

\section{Ergodic Theorems and Stationary Distributions}



\subsection{Absorbing Chains}

With a transition matrix $P$, we can find a permutation matrix $M$ that
permutes rows and columns (e.g. $M P M^T$) such that $P$ is organized into a
block matrix:

$$
P = \begin{pmatrix}
  I & 0 \\
  R & Q \\
\end{pmatrix}
$$

where $I$ is an identity matrix of absorbing states, $Q$ contains transitions
from non-absorbing to non-absorbing states, and $R$ contains transitions from
non-absorbing to absorbing states. Note that the $0$ matrix contains the
transitions from absorbing states to non-absorbing states, which are
necessarily all zero.

$$
P^2 = \begin{pmatrix}
  I & 0 \\
  R & Q \\
\end{pmatrix}
\begin{pmatrix}
  I & 0 \\
  R & Q \\
\end{pmatrix} = 
\begin{pmatrix}
  I & 0 \\
  R + QR & Q^2\\
\end{pmatrix}
$$

In general:

$$
P^t = \begin{pmatrix}
  I & 0 \\
  (I + Q + Q^2 + \ldots + Q^t)R & Q^t \\
\end{pmatrix}
$$

Note that since the row of $Q$ all sum to a value less than one (since
transitions from non-absorbing states to absorbing are excluded), the dominant
eigenvalue of $Q$, $\lambda_1 < 1$, so the system shrinks. Thus, $t \rightarrow
\infty$, $Q^t \rightarrow 0$. Thus:


$$
P^\infty = \begin{pmatrix}
  I & 0 \\
  NR & 0 \\
\end{pmatrix}
$$

where $N = (I + Q + Q^2 + Q^3 + \ldots)$; this is called the \emph{fundamental
matrix}.


\subsubsection{The Fundamental Matrix, and Expected Time until Absorption}

One property of interest of an absorbing matrix chain is how may times it
visits a state $j$ (given it starts in state $i$) before being absorbed. This
information is available via fundamental matrix described above. We'll cover
two ways of deriving this result.

\paragraph{Expectation approach} First, if $S_{i,j}$ is a random variable for the number of visits to $j$
starting from $i$. We can think of $S_{i,j}$ as the sum of indicator variables
that the chain enters non-absorbing state $j$ at time $k$ starting from state
$i$, e.g.:

$$
S_{i,j} = \mathbbm{1}_{\{X(0) = j | X(0) = i\}} + \mathbbm{1}_{\{X(1) = j | X(0) = i\}} + \mathbbm{1}_{\{X(2) = j | X(0) = i\}} + \ldots
$$

$$
\E[S_{i,j}] = \sum_{k=0}^\infty \E[\mathbbm{1}_{\{X(k) = j | X(0) = i\}}]
$$

by the fact that $\E[\mathbbm{1}_A] = P(A)$ (what Joe Blitzstein calls ``the
fundamental bridge"):

$$
\E[S_{i,j}] = \sum_{k=0}^\infty P(X(k) = j | X(0) = i)
$$

Note that $P(X(0) = j | X(0) = i) = 1$, and this is if and only if $i = j$;
intuitively, this is because the chain starts in state $i$ and we're counting
the expected number of visits to $j=i$.

From the general theory of Markov chains, we know that the probability a chain
transitions from state $i$ to $j$ in $k$ steps ($P(X(k) = j | X(0) = i$) is the
  $(i, j)$ entry of the matrix $Q^k$. For all states $i, j$ in the sample
  space, we can express the expected number of visits before absorption in a
  matrix $N$:

$$
N = \sum_{k=0}^{\infty} Q^k
$$

Where $N$ is a matrix containing entries $N_{i,j} = \E[S_{i,j}]$.

Note that $N$ is an infinite sum,

$$
N = I + Q + Q^2 + Q^3 + \ldots
$$

Which we can express: 

$$
N = I + QN
$$

$$
N = (I - Q)^{-1}
$$

\paragraph{Recursive approach} 

Alternatively, we can find this same formulation through a recursive approach.
We note that the expected number of times state $i$ is visited (starting from
state $i$) can be written as:

$$
N_{i,i} = 1 + \sum_k N_{i,k} Q_{k,i}
$$

where $k$ is all non-absorbing states. First, since the chain is initially in
state $i$, $N_{i,i}$ is incremented. Then, for each of these non-absorbing
states $k$ the chain will occupy, the probability it shifts to the state $i$ is
$Q_{k,i}$. More generally, we write:

$$
N_{i,j} = \delta_{ij} + \sum_k N_{i,k} Q_{k,j}
$$

\paragraph{Expected number of periods before absorption} 

With our fundamental matrix $N$, we can find the expected number of time spent
in \emph{any} non-absorbing state by summing over over these non-absorbing states:

$$
\E[S_i] = \sum_j N_{i,j}
$$




\printbibliography

\end{document}
